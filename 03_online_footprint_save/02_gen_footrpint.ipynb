{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from AlgorithmImports import *\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "from orchestrator import run\n",
    "from footprint_storage import get_year_file_path\n",
    "\n",
    "qb = QuantBook()\n",
    "symbol = qb.add_future(Futures.Indices.NASDAQ_100_E_MINI, Resolution.SECOND).symbol\n",
    "# Futures.Indices.NASDAQ_100_E_MINI SP_500_E_MINI Futures.Metals.Gold\n",
    "\n",
    "year=2022\n",
    "start = date(year, 1, 1)\n",
    "end = date(year, 12, 31)\n",
    "\n",
    "v_unit = 1000  # minimal volume unit per bar\n",
    "\n",
    "sec = qb.Securities[symbol]\n",
    "tick_size = sec.SymbolProperties.MinimumPriceVariation\n",
    "data_root=\"/QuantConnect/research-cloud/airlock/footprint_data\"\n",
    "run(qb=qb, symbol=symbol, start_date=start, end_date=end, v_unit=v_unit, tick_size=tick_size, force_recompute=False,data_root=data_root)\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从我们刚刚创建的文件中导入校验函数\n",
    "from validator import validate_daily_open\n",
    "\n",
    "\n",
    "# --- 执行 ---\n",
    "print(f\"开始校验合约: {symbol}\")\n",
    "print(f\"日期范围: {start} to {end}\")\n",
    "\n",
    "# ============== Cell 2: 运行校验 ==============\n",
    "print(\"\\n正在运行校验...\")\n",
    "# data_root 参数可以按需修改，这里使用模块中的默认值 '/LeanCLI/footprint_data'\n",
    "validation_errors = validate_daily_open(\n",
    "    qb=qb,\n",
    "    symbol=symbol,\n",
    "    start_date=start,\n",
    "    end_date=end,\n",
    "    data_root=data_root\n",
    ")\n",
    "print(\"校验完成。\")\n",
    "\n",
    "\n",
    "# ============== Cell 3: 显示结果 ==============\n",
    "print(\"\\n--- 校验结果 ---\")\n",
    "if not validation_errors:\n",
    "    print(\"✅ 校验通过！在指定日期范围内，所有日期的开盘价均在2个tick的容忍误差内。\")\n",
    "else:\n",
    "    print(f\"❌ 校验发现 {len(validation_errors)} 个问题。\")\n",
    "    \n",
    "    # 将结果转换为 DataFrame 以便清晰展示\n",
    "    errors_df = pd.DataFrame(validation_errors)\n",
    "    \n",
    "    # 计算差异的tick数量，以便更直观地判断\n",
    "    if \"difference\" in errors_df.columns and \"tick_size\" in errors_df.columns:\n",
    "        # 使用 .loc 避免 SettingWithCopyWarning\n",
    "        errors_df.loc[:, \"difference_in_ticks\"] = errors_df[\"difference\"] / errors_df[\"tick_size\"]\n",
    "    \n",
    "    # 为了更好的可读性，重新排列一下列的顺序\n",
    "    cols_order = [\n",
    "        \"date\", \"status\", \"daily_open\", \"daily_open_time\", \"footprint_open\", \"footprint_open_time\", \n",
    "        \"difference\", \"tick_size\", \"difference_in_ticks\", \"message\"\n",
    "    ]\n",
    "    \n",
    "    # 过滤掉在DataFrame中不存在的列\n",
    "    existing_cols = [col for col in cols_order if col in errors_df.columns]\n",
    "    \n",
    "    print(\"\\n详细信息:\")\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 1000):\n",
    "        print(errors_df[existing_cols].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 第1步：筛选符合正则的文件（支持 max_depth） ===\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "def find_files(base_dir=\".\", pattern=None, max_depth=None):\n",
    "    \"\"\"\n",
    "    遍历目录并筛选出符合正则的文件\n",
    "    :param base_dir: 要遍历的根目录\n",
    "    :param pattern: 文件名匹配正则表达式\n",
    "    :param max_depth: 最大遍历深度（None 表示不限制）\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir).resolve()\n",
    "    regex = re.compile(pattern) if pattern else None\n",
    "    matched_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        # 计算当前深度\n",
    "        depth = len(Path(root).relative_to(base_path).parts)\n",
    "        if max_depth is not None and depth > max_depth:\n",
    "            dirs[:] = []  # 不再深入\n",
    "            continue\n",
    "\n",
    "        for f in files:\n",
    "            fpath = Path(root) / f\n",
    "            if regex is None or regex.search(f):\n",
    "                matched_files.append(fpath)\n",
    "\n",
    "    print(f\"在目录 {base_path} 中找到 {len(matched_files)} 个匹配文件：\")\n",
    "    matched_files = sorted(matched_files, key=lambda x: str(x).lower())\n",
    "\n",
    "    for f in matched_files:\n",
    "        print(\"   \", f)\n",
    "    print(\"-\" * 60)\n",
    "    return matched_files\n",
    "\n",
    "\n",
    "# === 第2步：并行生成 Base64 下载链接 ===\n",
    "import base64\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def generate_base64_link(file_path):\n",
    "    \"\"\"\n",
    "    读取单个文件并生成 Base64 下载链接\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        encoded = base64.b64encode(f.read()).decode()\n",
    "    return f'<a download=\"{file_path}\" href=\"data:application/zip;base64,{encoded}\">下载 {file_name}</a>'\n",
    "\n",
    "def create_base64_links_parallel(files, max_workers=8):\n",
    "    \"\"\"\n",
    "    并行生成 Base64 下载链接并显示\n",
    "    \"\"\"\n",
    "    if not files:\n",
    "        return\n",
    "\n",
    "    print(f\" 开始并行生成 {len(files)} 个文件的 Base64 链接...\")\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(generate_base64_link, f): f for f in files}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            file_path = futures[future]\n",
    "            try:\n",
    "                link_html = future.result()\n",
    "                display(HTML(link_html))\n",
    "            except Exception as e:\n",
    "                print(f\"  生成 {file_path} 链接失败: {e}\")\n",
    "\n",
    "    print(f\" 全部完成，共生成 {len(files)} 个链接。\")\n",
    "\n",
    "def split_list(lst, chunk_size):\n",
    "    \"\"\"将列表按指定大小分块\"\"\"\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        yield lst[i:i + chunk_size]\n",
    "\n",
    "file_list=[]\n",
    "file_list += find_files(\"/QuantConnect/research-cloud/airlock/footprint_data\", pattern=rf\"{year}.*\", max_depth=2)\n",
    "\n",
    "batches = list(split_list(file_list, 20))\n",
    "\n",
    "print(f\"共计 {len(file_list)} 个匹配文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_base64_links_parallel(batches[0], max_workers=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foundation-Py-Default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
